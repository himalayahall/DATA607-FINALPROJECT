---
title: "Use Spark for EDA"
author: "Jawaid Hakim"
date: "`r Sys.Date()`"
output:
  
  html_document:
    
    toc: true
    toc_float: true
    number_sections: true
  pdf_document: 
    toc: true
    number_sections: true
boxlinks: true
urlcolor: blue
always_allow_html: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load library

```{r}
library(tidyverse)
library(sparklyr)
library(DBI)
```

Define functions to connect, disconnect from local master.

```{r}
Spark.ConnectLocal <- function() {
    sc <- spark_connect(master = "local")
    return (sc)
}

Spark.ConnectEdge <- function(master, home) {
    sc <- spark_connect(master = master, spark_home = home)
    return (sc)
}

Spark.ConnectStandalone <- function(hostname, port) {
    sc <- spark_connect(master = paste0("spark://", hostname, ":", port))
    return (sc)
}

Spark.Disconnect <- function(sc) {
    spark_disconnect(sc)
}

Spark.Web <- function(sc) {
    spark_web(sc)
}
```

Connect to local Spark standalone.

```{r connect-to-local-master}
sc <- Spark.ConnectLocal()
```

Display web console.

```{r display-web-console}
spark_web(sc)
```

Copy mtcars to cluster.

```{r}
cars <- copy_to(sc, mtcars, overwrite = TRUE)
```

```{r}
select(cars, hp, mpg) %>%
  sample_n(100) %>%
  collect() %>%
  plot()
```

Run usual R workflows against dataset, no change to syntax but data is in cluster.

```{r}
summarize_all(cars, mean) %>%
  show_query()
```


```{r}
summarize_all(cars, mean)
```

Run correlation across alll njumeric variables.

```{r}
ml_corr(cars)
```

Disconnect from cluster.

```{r}
Spark.Disconnect(sc)
```

