---
title: "DATA607 - COVID Data"
author: Josh Iden and Jawaid Hakim 
date: March 22, 2005
output:
     powerpoint_presentation:
            reference_doc: data607-finalproject.pptx

    
---

# Motivation

- Use COVID-19 datasets to explore global pandemic stats

- Explore relationships between COVID-19 prevalence and other datasets, e.g. mask policies, S&P500

# Data Acquisition - JHU CSSE [USA Daily Data](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us)

![US Daily](images/COVIDS-DAILY-US-DATA.PNG)

# Data Acquisition - JHU CSSE [Global timeseries](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)

![Global Timeseries](images/COVIDS-DAILY-GLOBAL-DATA.PNG)

# Data Acquisition - [Our World In Data](https://ourworldindata.org/coronavirus) 

![OWID Comprehensive Timeseries](images/COVIDS-DAILY-OWID.PNG)

# Data Wrangling - Strategy

- Common data extraction scripts/functions across datasets

    - Parallel processing
    
    - Table extraction (scraping) from HTML using Selenium/readr
    
    - Spark cluster interface

# Data Wrangling Milestones

- Github API [rate limits](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting). Implemented [OAuth authentication](https://docs.github.com/en/developers/apps/building-oauth-apps/authorizing-oauth-apps) to access Github via a personal account for higher limits.

- OWID dataset did not provide latitude/longitude variables which would be handy for map plots. Downloaded a separate dataset with country lat/long and (left-)joined with OWID for plotting on

# Data Exploration - Strategy

- Shiny for interactive data exploration

- Leaflet for map displays

- Spark for data analytics


# Tech Stack

- **Rselenium**: chosen for it's headless browser capability and getting around potential issues with embedded JavaScript. Used to extract daily data URLs
- **parallel**: chosen for efficiently processing remote data files using a local cluster
- **readr**: reading remote/local CSVs
- **leaflet**: render interactive global map
- **Spark/sparklr**: proof-of-concept for performing EDAs on large datasets in a Spark cluster. Since cloud hosted Spark services are either fee-based or time-limited we used a local cluster
- **AWS S3**: we looked into storing datasets on AWS S3 and leveraging Spark's built-in S3 connector. However, S3 storage rate-limits made  this impractical (20,000 GET Requests; 2,000 PUT, COPY, POST, or LIST Requests each month)
